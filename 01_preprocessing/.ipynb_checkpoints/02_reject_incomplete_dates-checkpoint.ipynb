{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read relevant data\n",
    "file = '../DATA/01_observations_decoded.csv'\n",
    "df = pd.read_csv(file, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by timestamp\n",
    "df_groups = df.groupby('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter days with low data volume\n",
    "def filter(groups):\n",
    "    result = []\n",
    "    cc = 1\n",
    "    l = len(groups)\n",
    "    step = 1\n",
    "    for date, data in groups:\n",
    "        # compute progress\n",
    "        perc = (cc/l)*100\n",
    "        if perc > step:\n",
    "            print('{0}: {1:.1f}%'.format(datetime.now(), perc))\n",
    "            step += 1\n",
    "        cc += 1\n",
    "        # filter low-vaulme data\n",
    "        if len(data) >= 129:\n",
    "            for idx, row in data.iterrows():\n",
    "                result.append([row['name'], row['east'], row['north'], row['up'], row['timestamp'], row['value']])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-17 14:18:34.991535: 1.0%\n",
      "2019-01-17 14:18:35.541392: 2.0%\n",
      "2019-01-17 14:18:36.081642: 3.0%\n",
      "2019-01-17 14:18:36.617340: 4.0%\n",
      "2019-01-17 14:18:37.171476: 5.0%\n",
      "2019-01-17 14:18:37.271747: 6.0%\n",
      "2019-01-17 14:18:37.691529: 7.0%\n",
      "2019-01-17 14:18:38.257783: 8.0%\n",
      "2019-01-17 14:18:38.801761: 9.0%\n",
      "2019-01-17 14:18:39.361324: 10.0%\n",
      "2019-01-17 14:18:39.909581: 11.0%\n",
      "2019-01-17 14:18:40.161592: 12.0%\n",
      "2019-01-17 14:18:40.416679: 13.0%\n",
      "2019-01-17 14:18:40.967684: 14.0%\n",
      "2019-01-17 14:18:41.511128: 15.0%\n",
      "2019-01-17 14:18:42.077424: 16.0%\n",
      "2019-01-17 14:18:42.611521: 17.0%\n",
      "2019-01-17 14:18:43.157563: 18.0%\n",
      "2019-01-17 14:18:43.577415: 19.0%\n",
      "2019-01-17 14:18:43.732377: 20.0%\n",
      "2019-01-17 14:18:44.197556: 21.0%\n",
      "2019-01-17 14:18:44.197556: 22.0%\n",
      "2019-01-17 14:18:44.267515: 23.0%\n",
      "2019-01-17 14:18:44.797475: 24.0%\n",
      "2019-01-17 14:18:45.267520: 25.0%\n",
      "2019-01-17 14:18:45.597630: 26.0%\n",
      "2019-01-17 14:18:45.777413: 27.0%\n",
      "2019-01-17 14:18:46.326786: 28.0%\n",
      "2019-01-17 14:18:46.781661: 29.0%\n",
      "2019-01-17 14:18:47.267579: 30.0%\n",
      "2019-01-17 14:18:47.807298: 31.0%\n",
      "2019-01-17 14:18:48.347583: 32.0%\n",
      "2019-01-17 14:18:48.881424: 33.0%\n",
      "2019-01-17 14:18:49.421239: 34.0%\n",
      "2019-01-17 14:18:49.957239: 35.0%\n",
      "2019-01-17 14:18:50.387354: 36.0%\n",
      "2019-01-17 14:18:50.701288: 37.0%\n",
      "2019-01-17 14:18:51.181341: 38.0%\n",
      "2019-01-17 14:18:51.701701: 39.0%\n",
      "2019-01-17 14:18:52.228049: 40.0%\n",
      "2019-01-17 14:18:52.777625: 41.0%\n",
      "2019-01-17 14:18:53.307482: 42.0%\n",
      "2019-01-17 14:18:53.807638: 43.0%\n",
      "2019-01-17 14:18:54.107376: 44.0%\n",
      "2019-01-17 14:18:54.567561: 45.0%\n",
      "2019-01-17 14:18:55.047422: 46.0%\n",
      "2019-01-17 14:18:55.497368: 47.0%\n",
      "2019-01-17 14:18:55.667470: 48.0%\n",
      "2019-01-17 14:18:56.121544: 49.0%\n",
      "2019-01-17 14:18:56.667463: 50.0%\n",
      "2019-01-17 14:18:57.197725: 51.0%\n",
      "2019-01-17 14:18:57.741465: 52.0%\n",
      "2019-01-17 14:18:58.287367: 53.0%\n",
      "2019-01-17 14:18:58.887678: 54.0%\n",
      "2019-01-17 14:18:59.427350: 55.0%\n",
      "2019-01-17 14:18:59.946676: 56.0%\n",
      "2019-01-17 14:19:00.039858: 57.0%\n",
      "2019-01-17 14:19:00.281564: 58.0%\n",
      "2019-01-17 14:19:00.791687: 59.0%\n",
      "2019-01-17 14:19:01.311487: 60.0%\n",
      "2019-01-17 14:19:01.767441: 61.0%\n",
      "2019-01-17 14:19:02.146554: 62.0%\n",
      "2019-01-17 14:19:02.637430: 63.0%\n",
      "2019-01-17 14:19:03.171728: 64.0%\n",
      "2019-01-17 14:19:03.697412: 65.0%\n",
      "2019-01-17 14:19:04.007547: 66.0%\n",
      "2019-01-17 14:19:04.541798: 67.0%\n",
      "2019-01-17 14:19:04.707297: 68.0%\n",
      "2019-01-17 14:19:05.061550: 69.0%\n",
      "2019-01-17 14:19:05.556647: 70.0%\n",
      "2019-01-17 14:19:06.081426: 71.0%\n",
      "2019-01-17 14:19:06.591273: 72.0%\n",
      "2019-01-17 14:19:07.147380: 73.0%\n",
      "2019-01-17 14:19:07.681463: 74.0%\n",
      "2019-01-17 14:19:07.972050: 75.0%\n",
      "2019-01-17 14:19:08.507532: 76.0%\n",
      "2019-01-17 14:19:09.037674: 77.0%\n",
      "2019-01-17 14:19:09.577516: 78.0%\n",
      "2019-01-17 14:19:09.637514: 79.0%\n",
      "2019-01-17 14:19:09.651483: 80.0%\n",
      "2019-01-17 14:19:10.059033: 81.0%\n",
      "2019-01-17 14:19:10.341306: 82.0%\n",
      "2019-01-17 14:19:10.857729: 83.0%\n",
      "2019-01-17 14:19:11.366339: 84.0%\n",
      "2019-01-17 14:19:11.947670: 85.0%\n",
      "2019-01-17 14:19:12.461044: 86.0%\n",
      "2019-01-17 14:19:13.007242: 87.0%\n",
      "2019-01-17 14:19:13.537567: 88.0%\n",
      "2019-01-17 14:19:14.077191: 89.0%\n",
      "2019-01-17 14:19:14.607571: 90.0%\n",
      "2019-01-17 14:19:15.168042: 91.0%\n",
      "2019-01-17 14:19:15.687465: 92.0%\n",
      "2019-01-17 14:19:16.217554: 93.0%\n",
      "2019-01-17 14:19:16.707501: 94.0%\n",
      "2019-01-17 14:19:17.251699: 95.0%\n",
      "2019-01-17 14:19:17.817618: 96.0%\n",
      "2019-01-17 14:19:18.076734: 97.0%\n",
      "2019-01-17 14:19:18.621229: 98.0%\n",
      "2019-01-17 14:19:19.161564: 99.0%\n"
     ]
    }
   ],
   "source": [
    "# run function, create and export dataframe as csv\n",
    "data = filter(df_groups)\n",
    "result = pd.DataFrame(data=data, columns=df.columns)\n",
    "result.sort_values(['timestamp', 'name'])\n",
    "result.to_csv('../DATA/02_observations_high-data-volume.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
